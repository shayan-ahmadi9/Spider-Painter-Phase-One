{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3179bc8",
   "metadata": {},
   "source": [
    "# What's New in This Version\n",
    "\n",
    "1. Using color detection without LED\n",
    "\n",
    "2. Using average of different edges of the marker to calculate PixelsPerMetric\n",
    "\n",
    "3. Also we used a manual ppm based on the starting point of the Object of Interest (OOI). Therefore for each run, its value    should be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0752077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "#print(cv2.__version__)\n",
    "import cv2.aruco as aruco\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "from imutils import perspective\n",
    "from imutils import contours\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d858c7",
   "metadata": {},
   "source": [
    "### Color Detection\n",
    "If the code did not detect the object, uncomment the following code and run only the following block to adjust the needed parameters in order to find the object. Then use this numbers in the first lines of the code:\n",
    "\n",
    "Define the lower and upper bounds of the green color in HSV color space\n",
    "green_lower = (29, 86, 6)\n",
    "green_upper = (64, 255, 255)\n",
    "\n",
    "<p style=\"color:green;\">\n",
    "Best range for green colors is:\n",
    "    <br>\n",
    "green_lower = (24, 66, 0)\n",
    "    <br>\n",
    "green_upper = (101, 255, 255)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010bf326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def onTrack1(val):\n",
    "#     global hueLow\n",
    "#     hueLow=val\n",
    "#     #print('Hue Low',hueLow)\n",
    "# def onTrack2(val):\n",
    "#     global hueHigh\n",
    "#     hueHigh=val\n",
    "#     #print('Hue High',hueHigh)\n",
    "# def onTrack3(val):\n",
    "#     global satLow\n",
    "#     satLow=val\n",
    "#     #print('Sat Low',satLow)\n",
    "# def onTrack4(val):\n",
    "#     global satHigh\n",
    "#     satHigh=val\n",
    "#     #print('Sat High',satHigh)\n",
    "# def onTrack5(val):\n",
    "#     global valLow\n",
    "#     valLow=val\n",
    "#     #print('Val Low',valLow)\n",
    "# def onTrack6(val):\n",
    "#     global valHigh\n",
    "#     valHigh=val\n",
    "#     #print('Val High',valHigh)\n",
    " \n",
    "# width=640\n",
    "# height=360\n",
    "# cam=cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "# cam.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "# cam.set(cv2.CAP_PROP_FRAME_HEIGHT,height)\n",
    "# cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "# cam.set(cv2.CAP_PROP_FOURCC,cv2.VideoWriter_fourcc(*'MJPG'))\n",
    " \n",
    "# cv2.namedWindow('myTracker')\n",
    "# cv2.moveWindow('myTracker',width,0)\n",
    " \n",
    "# hueLow=0\n",
    "# hueHigh=179\n",
    "# satLow=0\n",
    "# satHigh=255\n",
    "# valLow=0\n",
    "# valHigh=255\n",
    " \n",
    "# cv2.createTrackbar('Hue Low','myTracker',0,179,onTrack1)\n",
    "# cv2.createTrackbar('Hue High','myTracker',179,179,onTrack2)\n",
    "# cv2.createTrackbar('Sat Low','myTracker',0,255,onTrack3)\n",
    "# cv2.createTrackbar('Sat High','myTracker',255,255,onTrack4)\n",
    "# cv2.createTrackbar('Val Low','myTracker',0,255,onTrack5)\n",
    "# cv2.createTrackbar('Val High','myTracker',255,255,onTrack6)\n",
    " \n",
    "# while True:\n",
    "#     ignore,  frame = cam.read()\n",
    "#     frameHSV=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "#     lowerBound=np.array([hueLow,satLow,valLow])\n",
    "#     upperBound=np.array([hueHigh,satHigh,valHigh])\n",
    "#     myMask=cv2.inRange(frameHSV,lowerBound,upperBound)\n",
    "#     #myMask=cv2.bitwise_not(myMask)\n",
    "#     myObject=cv2.bitwise_and(frame,frame,mask=myMask)\n",
    "#     myObjectSmall=cv2.resize(myObject,(int(width/2),int(height/2)))\n",
    "#     cv2.imshow('My Object',myObjectSmall)\n",
    "#     cv2.moveWindow('My Object',int(width/2),int(height))\n",
    "#     myMaskSmall=cv2.resize(myMask,(int(width/2),int(height/2)))\n",
    "#     cv2.imshow('My Mask',myMaskSmall)\n",
    "#     cv2.moveWindow('My Mask',0,height)\n",
    "#     cv2.imshow('my WEBcam', frame)\n",
    "#     cv2.moveWindow('my WEBcam',0,0)\n",
    "#     if cv2.waitKey(1) & 0xff ==ord('q'):\n",
    "#         break\n",
    "# cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e383e9c",
   "metadata": {},
   "source": [
    "## aruco_finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38cd529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_aruco_marker(img):\n",
    "    aruco_dict = aruco.Dictionary_get(aruco.DICT_ARUCO_ORIGINAL)\n",
    "\n",
    "    # Marker detection parameters\n",
    "    parameters = aruco.DetectorParameters_create()\n",
    "\n",
    "    # Lists of ids and the corners belonging to each id\n",
    "    corners, ids, rejected_points = aruco.detectMarkers(img, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # Draw what the aruco detector sees\n",
    "    image = img.copy()\n",
    "    aruco.drawDetectedMarkers(image, corners)\n",
    "    cv2.imwrite(\"./output/Marker.jpg\", image)\n",
    "\n",
    "    # return only the first marker on the list\n",
    "    return corners[0][0]\n",
    "\n",
    "\n",
    "def get_calibration_data():\n",
    "    \"\"\"\n",
    "    The distortion coefficient retrieved is for a specific camera; images taken on another camera may produce different results.\n",
    "    \"\"\"\n",
    "    # Read Yaml file and retrieve distortion coefficient and camera matrix\n",
    "    calibration_file = cv2.FileStorage(\"./calibration.yaml\", cv2.FileStorage_READ)\n",
    "    file_node = calibration_file.getNode('camera_matrix')\n",
    "    matrix = np.asarray(file_node.mat())\n",
    "    file_node = calibration_file.getNode('dist_coeff')\n",
    "    distortion = np.asarray(file_node.mat())\n",
    "\n",
    "    return matrix, distortion\n",
    "\n",
    "\n",
    "def calibrate_image(img, matrix, distortion, new_width=1280, new_height=960):\n",
    "\n",
    "    # start by scaling all input images\n",
    "    new_img = cv2.resize(img, (new_width, new_height))\n",
    "\n",
    "    # Get height/width of image\n",
    "    h, w = new_img.shape[:2]\n",
    "\n",
    "    # commented out due to bad warping of objects.\n",
    "    # new_camera_mtx, roi = cv2.getOptimalNewCameraMatrix(matrix, distortion, (w, h), 1, (w, h))\n",
    "    # undistorted_img = cv2.undistort(new_img, matrix, distortion, None, new_camera_mtx)\n",
    "\n",
    "    undistorted_img = new_img\n",
    "\n",
    "    # Crop the image to remove the black border (warped distortion)\n",
    "    # this cropping is too aggressive for our needs, so it is left commented out.\n",
    "    # x, y, width, height = roi\n",
    "    # cropped_img = undistorted_img[y:y+height, x:x+width]\n",
    "\n",
    "    return undistorted_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e63e60",
   "metadata": {},
   "source": [
    "## object_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f275f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python main.py -i ./input/Straps1.jpg\n",
    "# python main.py -i ./input/Generated/angle75.png\n",
    "\n",
    "def midpoint(ptA, ptB):\n",
    "    return (ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5\n",
    "\n",
    "def objectsize(image,c, pixelsPerMetric):\n",
    "# \tprint(\"WE RECIEVED:\", marker)\n",
    "# \t# convert image to grayscale, and blur it slightly\n",
    "# \tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# \tgray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "# \t# perform edge detection, then perform a dilation + erosion to\n",
    "# \t# close gaps in between object edges\n",
    "# \tedged = cv2.Canny(gray, 15, 100)\n",
    "# \tedged = cv2.dilate(edged, None, iterations=1)\n",
    "# \tedged = cv2.erode(edged, None, iterations=1)\n",
    "\n",
    "# \t# cv2.imshow(\"Edges\", edged)\n",
    "# \tcv2.imwrite(\"./output/edges.jpg\", edged)\n",
    "# \tcv2.waitKey(0)\n",
    "\n",
    "# \t# find contours in the edge map\n",
    "# \tcnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
    "# \t\t\t\t\t\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "# \tcnts = imutils.grab_contours(cnts)\n",
    "\n",
    "# \t# sort the contours from left-to-right and initialize the\n",
    "# \t# 'pixels per metric' calibration variable\n",
    "# \t(cnts, _) = contours.sort_contours(cnts)\n",
    "\tboxes = []\n",
    "\n",
    "\t# loop over the contours individually\n",
    "\n",
    "#     # if the contour is not sufficiently large, ignore it\n",
    "#     if cv2.contourArea(c) < 100:\n",
    "#         continue\n",
    "    # compute the rotated bounding box of the contour\n",
    "\tbox = cv2.minAreaRect(c)\n",
    "\tbox = cv2.boxPoints(box)\n",
    "\tbox = np.array(box, dtype=\"int\")\n",
    "\n",
    "\t\t# order the points in the contour such that they appear\n",
    "\t\t# in top-left, top-right, bottom-right, and bottom-left\n",
    "\t\t# order, then draw the outline of the rotated bounding\n",
    "\t\t# box\n",
    "\tbox = perspective.order_points(box)\n",
    "\tboxes.append(box)\n",
    "\n",
    "# \tminDist = 99999.\n",
    "# \tfor box in boxes:  # loop through boxes to find the one closest to the aruco marker, set the PPM\n",
    "# \t\tdistance = abs(box[2][0]-marker[0])+abs(box[2][1]-marker[1])  # rough difference between marker and current box\n",
    "# \t\tprint(\"contour:\", box[2])\n",
    "# \t\tprint(\"distance:\", distance)\n",
    "# \t\tif distance < minDist:  # Identifies potential markers:  the correct box will have the smallest distance\n",
    "# \t\t\tprint(\"CLOSEST contour:\", box[2])\n",
    "# \t\t\tminDist = distance\n",
    "# \t\t\tpixelsPerMetric = dist.euclidean(box[2], box[1]) / 8  # calculates vertical length of the marker\n",
    "\n",
    "\toutName = 1\n",
    "\tfor box in boxes:\n",
    "\t\torig = image.copy()\n",
    "\t\tcv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n",
    "\n",
    "\t# loop over the original points and draw them\n",
    "\t\tfor (x, y) in box:\n",
    "\t\t\tcv2.circle(orig, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "\n",
    "\t\t# unpack the ordered bounding box, then compute the midpoint\n",
    "\t\t# between the top-left and top-right coordinates, followed by\n",
    "\t\t# the midpoint between bottom-left and bottom-right coordinates\n",
    "\t\t(tl, tr, br, bl) = box\n",
    "\t\t(tltrX, tltrY) = midpoint(tl, tr)\n",
    "\t\t(blbrX, blbrY) = midpoint(bl, br)\n",
    "\n",
    "\t\t# compute the midpoint between the top-left and top-right points,\n",
    "\t\t# followed by the midpoint between the top-righ and bottom-right\n",
    "\t\t(tlblX, tlblY) = midpoint(tl, bl)\n",
    "\t\t(trbrX, trbrY) = midpoint(tr, br)\n",
    "\n",
    "\t\t# draw the midpoints on the image\n",
    "\t\tcv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n",
    "\t\tcv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n",
    "\t\tcv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n",
    "\t\tcv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n",
    "\n",
    "\t\t# draw lines between the midpoints\n",
    "\t\tcv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),\n",
    "\t\t\t\t (255, 0, 255), 2)\n",
    "\t\tcv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),\n",
    "\t\t\t\t (255, 0, 255), 2)\n",
    "\n",
    "\t\t# compute the Euclidean distance between the midpoints\n",
    "\t\tdA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n",
    "\t\tdB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n",
    "\n",
    "\n",
    "\t\t# compute the size of the object\n",
    "\t\tdimA = dA / pixelsPerMetric\n",
    "\t\tdimB = dB / pixelsPerMetric\n",
    "\n",
    "\t\t# draw the object sizes on the image\n",
    "\t\tcv2.putText(orig, \"{:.1f}cm\".format(dimB),\n",
    "\t\t\t\t\t(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t\t\t\t0.65, (255, 64, 64), 2)\n",
    "\t\tcv2.putText(orig, \"{:.1f}cm\".format(dimA),\n",
    "\t\t\t\t\t(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t\t\t\t0.65, (255, 64, 64), 2)\n",
    "# \t\tprint(\"Object \" + str(outName)+\": \" + \"{:.1f}cm\".format(dimB) + \" by {:.1f}cm\".format(dimA))\n",
    "\t\t# show the output image\n",
    "\t\t# cv2.imshow(\"Image\", orig)\n",
    "\t\tcv2.imwrite(\"./output/object \"+str(outName)+\".jpg\", orig)\n",
    "\t\toutName = outName+1\n",
    "\t\tcv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0df58",
   "metadata": {},
   "source": [
    "## transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe6d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeEmpty(img):\n",
    "\t# this function removes pitch black space created when the transformed image\n",
    "\t# generates empty space not part of the original.\n",
    "\th, w, _ = img.shape\n",
    "\tprint(h, w)\n",
    "\tcv2.imwrite(\"./output/no crop.jpg\", img)\n",
    "\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\tcv2.imwrite(\"./output/no crop bw.jpg\", gray)\n",
    "\tminx = 9999999\n",
    "\tmaxx = 0\n",
    "\tminy = 9999999\n",
    "\tmaxy = 0\n",
    "\n",
    "\tfor y in range(h-1):\n",
    "\t\tfor x in range(w-1):\n",
    "\t\t\tif gray[y, x] != 0:\n",
    "\t\t\t\tif miny == 9999999:\n",
    "\t\t\t\t\tminy = y\n",
    "\t\t\t\tif maxx < x:\n",
    "\t\t\t\t\tmaxx = x\n",
    "\t\t\t\tif minx > x:\n",
    "\t\t\t\t\tminx = x\n",
    "\t\t\t\tmaxy = y\n",
    "\n",
    "\tprint(miny, maxy, minx, maxx)\n",
    "\n",
    "\timg2 = img[miny+10:maxy-10, minx+10:maxx-10]\n",
    "\treturn img2\n",
    "\n",
    "\n",
    "def GetPadding(img, pts):\n",
    "\t#print(\"noob\",img.shape)\n",
    "\theight, width, _ = img.shape\n",
    "\treturn height, height, width, width\n",
    "\t# 310, 3400, 640, 700\n",
    "\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "\t# Calculate the space needed on all sides of the aruco marker\n",
    "\tpadUp, padDown, padLeft, padRight = GetPadding(image, pts)\n",
    "\trect = pts\n",
    "\t(tl, tr, br, bl) = rect\n",
    "\t#print(rect)\n",
    "\n",
    "\t# compute the width of the new image, which will be the\n",
    "\t# maximum distance between bottom-right and bottom-left\n",
    "\t# x-coordiates or the top-right and top-left x-coordinates\n",
    "\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\tmaxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "\t# compute the height of the new image, which will be the\n",
    "\t# maximum distance between the top-right and bottom-right\n",
    "\t# y-coordinates or the top-left and bottom-left y-coordinates\n",
    "\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "\tmaxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "\tmaxSize = max(int(maxHeight), int(maxWidth))\n",
    "\t# now that we have the dimensions of the new image, construct\n",
    "\t# the set of destination points to obtain a \"birds eye view\",\n",
    "\t# (i.e. top-down view) of the image, again specifying points\n",
    "\t# in the top-left, top-right, bottom-right, and bottom-left\n",
    "\t# order\n",
    "\tdst = np.array([\n",
    "\t\t[padLeft, padUp],\n",
    "\t\t[padLeft+maxSize, padUp],\n",
    "\t\t[padLeft+maxSize, padUp+maxSize],\n",
    "\t\t[padLeft, padUp+maxSize]], dtype=\"float32\")\n",
    "\n",
    "\t# compute the perspective transform matrix and then apply it\n",
    "\tM = cv2.getPerspectiveTransform(rect, dst)\n",
    "\t#print(M)\n",
    "\t# Apply perspective transform to the image\n",
    "\twarped = cv2.warpPerspective(image, M, (maxSize+padRight+padLeft, maxSize+padDown+padUp))\n",
    "# \t# remove empty space added by the warp\n",
    "# \twarped = removeEmpty(warped)\n",
    "\t# return the warped image\n",
    "\treturn warped, dst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a2b646",
   "metadata": {},
   "source": [
    "# Cursor Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "312923b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the callback function for mouse events\n",
    "# def mouse_callback(event, x, y, flags, param):\n",
    "#     if event == cv2.EVENT_MOUSEMOVE:\n",
    "#         # Clear the previous position by drawing a black rectangle over it\n",
    "#         img_copy = img.copy()\n",
    "#         cv2.rectangle(img_copy, (0, 0), (200, 50), (0, 0, 0), -1)\n",
    "\n",
    "#         # Update the image with the current cursor position\n",
    "#         font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#         pos = \"Position: ({}, {})\".format(x, y)\n",
    "#         cv2.putText(img_copy, pos, (10, 30), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "#         # Display the updated image\n",
    "#         cv2.imshow(\"Image\", img_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac493002",
   "metadata": {},
   "source": [
    "# Calculate the distance between the main object and the origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb7a74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_calculator(x_object, y_object, x_origin, y_origin):\n",
    "    \n",
    "    x_distance = (x_object - x_origin)\n",
    "    y_distance = abs(y_object - y_origin)\n",
    "    \n",
    "    # convert pixel to cm\n",
    "    x_distance = x_distance / pixelsPerMetric\n",
    "    y_distance = y_distance / pixelsPerMetric\n",
    "    \n",
    "    return x_distance , y_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9911746f",
   "metadata": {},
   "source": [
    "# the Main while loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c2534d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPM:  10.400120162963868\n",
      "10.400120162963868\n",
      "10.408603545998751\n",
      "10.401816839570845\n",
      "detected values: \n",
      "59.60497185851042 60.37406826958797\n",
      "detected values: \n",
      "39.41619106772463 60.37406826958797\n",
      "detected values: \n",
      "19.419684379708233 60.08565711543389\n",
      "detected values: \n",
      "-0.2884111541540827 59.989520064049195\n",
      "detected values: \n",
      "59.60497185851042 40.28142453018688\n",
      "detected values: \n",
      "39.32005401633994 40.18528747880219\n",
      "detected values: \n",
      "19.419684379708233 40.08915042741749\n",
      "detected values: \n",
      "-0.09613705138469422 40.08915042741749\n",
      "detected values: \n",
      "59.60497185851042 19.9965066880164\n",
      "detected values: \n",
      "39.41619106772463 20.092643739401094\n",
      "detected values: \n",
      "19.611958482477622 20.18878079078579\n",
      "detected values: \n",
      "0.0 19.9965066880164\n",
      "detected values: \n",
      "59.797245961279806 0.19227410276938844\n",
      "detected values: \n",
      "39.704602221878716 0.0\n",
      "detected values: \n",
      "19.708095533862316 0.0\n",
      "detected values: \n",
      "19.80423258524701 0.0\n"
     ]
    }
   ],
   "source": [
    "#=====================================================\n",
    "#========================INPUT========================\n",
    "#=====================================================\n",
    "start_point_x = 60\n",
    "start_point_y = 60\n",
    "\n",
    "Is_red_detected = False\n",
    "arduino_list = []\n",
    "detector_list = []\n",
    "center_points = []\n",
    "prev_center_x, prev_center_y, prev_center_x1, prev_center_y1 = 0, 0, 0, 0\n",
    "#=====================================================\n",
    "\n",
    "#serial communication\n",
    "# import serial\n",
    "# import time\n",
    "# arduino = serial.Serial(port='COM3', baudrate=9600, timeout=.2)\n",
    "\n",
    "#===============================================\n",
    "# Define the lower and upper bounds of the green color in HSV color space\n",
    "\n",
    "# green_lower = (24, 66, 0)\n",
    "# green_upper = (101, 255, 255)\n",
    "\n",
    "green_lower = (36, 68, 0)\n",
    "green_upper = (167, 255, 255)\n",
    "\n",
    "# green_lower = (37, 78, 0)\n",
    "# green_upper = (50, 255, 255)\n",
    "\n",
    "# red_lower = (174, 147, 101)\n",
    "# red_upper = (179, 217, 142)\n",
    "\n",
    "# green_lower = (38,82,45)\n",
    "# green_upper = (62,255,255)\n",
    "\n",
    "# red_lower = (68, 0, 0)\n",
    "# red_upper = (152, 255, 255)\n",
    "\n",
    "red_lower = (20,155,0)\n",
    "red_upper = (179,255,255)\n",
    "\n",
    "# red_lower = (102,168,29)\n",
    "# red_upper = (122,255,131)\n",
    "#==================================================\n",
    "\n",
    "# Define the kernel for morphological operations\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n",
    "\n",
    "# Define the initial position and center of the object\n",
    "x, y, w, h = 0, 0, 0, 0\n",
    "center_x, center_y, prev_center_y, prev_center_x = 0, 0, 0, 0\n",
    "\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# cap.set(cv2.CAP_PROP_FPS, 10)\n",
    "\n",
    "# img = cv2.imread(\"test3.jpg\", cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Check if the video file was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit()\n",
    "\n",
    "#--------------------------------------------------\n",
    "#Find the marker in the first frame and caculate the PPM\n",
    "\n",
    "# Read a frame from the video\n",
    "ret, img = cap.read()\n",
    "# get and process the camera calibration to warp the image\n",
    "matrix, distortion = get_calibration_data()\n",
    "calibrated_img = calibrate_image(img, matrix, distortion)\n",
    "\n",
    "# find the marker in the image\n",
    "marker = find_aruco_marker(calibrated_img)\n",
    "\n",
    "calibrated_img = calibrate_image(img, matrix, distortion)\n",
    "\n",
    "# transform the image to be bird's eye view\n",
    "trans_image, dst = four_point_transform(calibrated_img, marker)\n",
    "\n",
    "# find the location of the marker in the transformed image\n",
    "trans_marker = find_aruco_marker(trans_image)\n",
    "\n",
    "# calculate the pixels per metric for the image.  This represents how many pixels are in a cm.\n",
    "distance_top = dist.euclidean(trans_marker[0], trans_marker[1]) / 20\n",
    "distance_right = dist.euclidean(trans_marker[1], trans_marker[2]) / 20\n",
    "distance_bottom = dist.euclidean(trans_marker[2], trans_marker[3]) / 20\n",
    "distance_left = dist.euclidean(trans_marker[3], trans_marker[0]) / 20\n",
    "\n",
    "pixelsPerMetric = (distance_top+distance_right+distance_bottom+distance_left) / 4\n",
    "\n",
    "# pixelsPerMetric = dist.euclidean(trans_marker[2], trans_marker[1]) / 20\n",
    "print(\"PPM: \", pixelsPerMetric)\n",
    "\n",
    "#--------------------------------------------------\n",
    "    \n",
    "# Loop through the frames of the video\n",
    "while True:\n",
    "    \n",
    "    # Read a frame from the video\n",
    "    ret, img = cap.read()\n",
    "    #If the frame cannot be read, break out of the loop\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # get and process the camera calibration to warp the image\n",
    "    calibrated_img = calibrate_image(img, matrix, distortion)\n",
    "\n",
    "    # transform the image to be bird's eye view\n",
    "    trans_image, dst = four_point_transform(calibrated_img, marker)\n",
    "#     cv2.imwrite(\"./output/transformed.jpg\", trans_image)\n",
    "\n",
    "#     # find the location of the marker in the transformed image\n",
    "#     trans_marker = find_aruco_marker(trans_image)\n",
    "\n",
    "    # Check if the user pressed the 'q' key to quit\n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #     break\n",
    "    # elif cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "    #     # Print the width and height of the whiteboard\n",
    "    #     print(\"Whiteboard width:\", width)\n",
    "    #     print(\"Whiteboard height:\", height)\n",
    "    \n",
    "    #=========================================================================================\n",
    "    # Convert the frame from BGR color space to HSV color space\n",
    "    hsv = cv2.cvtColor(trans_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Threshold the image to get the green color region\n",
    "    mask = cv2.inRange(hsv, green_lower, green_upper)\n",
    "\n",
    "    # Perform morphological operations to remove noise\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(contours) > 0:\n",
    "        # Get the contour with the largest area\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "        # pass the rotated image as well as the bottom right coordinates of the aruco marker\n",
    "        objectsize(trans_image, max_contour, pixelsPerMetric)\n",
    "        # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "        \n",
    "        # Get the bounding rectangle of the contour\n",
    "        x, y, w, h = cv2.boundingRect(max_contour)\n",
    "\n",
    "        # Draw a green rectangle around the object\n",
    "        cv2.rectangle(trans_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Get the center of the bounding rectangle\n",
    "        center_x, center_y = x + w // 2, y + h // 2\n",
    "        \n",
    "        # Append the center point to the list\n",
    "        center_points.append((center_x, center_y))\n",
    "        \n",
    "    # Draw circles for each center point in the list\n",
    "    #for point in center_points:\n",
    "        #cv2.circle(img, point, 4, (0, 0, 255), -1)\n",
    "    if (not contours):\n",
    "        center_x, center_y = 0, 0\n",
    "        center_points = []\n",
    "    \n",
    "    if (contours):\n",
    "\n",
    "        # Draw a line connecting the centers of the bounding rectangles in consecutive frames\n",
    "        if len(center_points) > 1:\n",
    "            for i in range(1, len(center_points)):\n",
    "                cv2.line(trans_image, center_points[i-1], center_points[i], (255, 0, 0), 2)\n",
    "\n",
    "    # Draw a circle at the center of the bounding rectangle\n",
    "    #cv2.circle(trans_image, (center_x, center_y), 4, (0, 0, 255), -1)\n",
    "    \n",
    "    # Draw a line connecting the centers of the bounding rectangles in consecutive frames\n",
    "    #if x != 0 and y != 0:\n",
    "        #cv2.line(trans_image, (center_x, center_y), (prev_center_x, prev_center_y), (255, 0, 0), 2)\n",
    "        \n",
    "    # Show the video capture with the green object tracked\n",
    "    #cv2.imshow('Green Object Tracker', trans_image)\n",
    "\n",
    "    # Set the previous center of the object to the current center\n",
    "    prev_center_x, prev_center_y = center_x, center_y\n",
    "\n",
    "    #=========================================================================================\n",
    "    if Is_red_detected == False:\n",
    "        # Convert the frame from BGR color space to HSV color space\n",
    "        hsv1 = cv2.cvtColor(trans_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Threshold the image to get the green color region\n",
    "        mask1 = cv2.inRange(hsv1, red_lower, red_upper)\n",
    "\n",
    "        # Perform morphological operations to remove noise\n",
    "        mask1 = cv2.morphologyEx(mask1, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Find contours in the thresholded image\n",
    "        contours1, hierarchy1 = cv2.findContours(mask1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if len(contours1) > 0:\n",
    "            # Get the contour with the largest area\n",
    "            max_contour1 = max(contours1, key=cv2.contourArea)\n",
    "\n",
    "            # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "            # pass the rotated image as well as the bottom right coordinates of the aruco marker\n",
    "            objectsize(trans_image, max_contour1, pixelsPerMetric)\n",
    "            # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "            # Get the bounding rectangle of the contour\n",
    "            x1, y1, w1, h1 = cv2.boundingRect(max_contour1)\n",
    "\n",
    "            # Draw a green rectangle around the object\n",
    "            cv2.rectangle(trans_image, (x1, y1), (x1 + w1, y1 + h1), (255, 0, 0), 2)\n",
    "\n",
    "            # Get the center of the bounding rectangle\n",
    "            center_x1, center_y1 = x1 + w1 // 2, y1 + h1 // 2\n",
    "\n",
    "        # Draw a circle at the center of the bounding rectangle\n",
    "        cv2.circle(trans_image, (center_x1, center_y1), 4, (0, 0, 255), -1)\n",
    "\n",
    "        # Draw a line connecting the centers of the bounding rectangles in consecutive frames\n",
    "        if x1 != 0 and y1 != 0:\n",
    "            cv2.line(trans_image, (center_x1, center_y1), (prev_center_x1, prev_center_y1), (255, 0, 0), 2)\n",
    "\n",
    "        # Show the video capture with the green object tracked\n",
    "    #     cv2.imshow('Green Object Tracker', trans_image)\n",
    "\n",
    "        # Set the previous center of the object to the current center\n",
    "        prev_center_x1, prev_center_y1 = center_x1, center_y1\n",
    "        \n",
    "        print(pixelsPerMetric)\n",
    "        # claculates a manual ppm based on the starting point of the object of intereset (OOI)\n",
    "        manual_ppm = dist.euclidean((center_x1,center_y1), (center_x, center_y)) / (np.sqrt(start_point_x**2 + start_point_y**2))\n",
    "        print(manual_ppm)\n",
    "        # Clacluates the new PixelsPerMetric by adding the new manual ppm\n",
    "        pixelsPerMetric = (distance_top+distance_right+distance_bottom+distance_left+manual_ppm) / 5\n",
    "        print(pixelsPerMetric)\n",
    "        \n",
    "        Is_red_detected = True\n",
    "    \n",
    "    # Draw a green rectangle around the object\n",
    "    cv2.rectangle(trans_image, (x1, y1), (x1 + w1, y1 + h1), (255, 0, 0), 2)\n",
    "    # Draw a circle at the center of the bounding rectangle\n",
    "    cv2.circle(trans_image, (center_x1, center_y1), 4, (0, 0, 255), -1)\n",
    "    \n",
    "    #=========================================================================================\n",
    "    # Create a window and set the mouse callback function\n",
    "    #cv2.namedWindow(\"Scanned Image\")\n",
    "    #cv2.setMouseCallback(\"Scanned Image\", mouse_callback)\n",
    "    #=========================================================================================\n",
    "    # Display the result\n",
    "    cv2.namedWindow(\"Scanned Image\", cv2.WINDOW_NORMAL)   \n",
    "    cv2.imshow(\"Scanned Image\", trans_image)\n",
    "    \n",
    "    x_coordinate, y_coordinate = position_calculator(center_x, center_y, center_x1, center_y1 )\n",
    "    \n",
    "    #================================================\n",
    "    #Serial Communication\n",
    "    \n",
    "#     iterator = 0\n",
    "#     while iterator<2:\n",
    "#         line = arduino.readline()   # read a byte\n",
    "#         if line:\n",
    "#             string = line.decode()  # convert the byte string to a unicode string\n",
    "#             string = string.strip()\n",
    "#             num = (string) # convert the unicode string to an int\n",
    "#             if iterator%2 == 0:\n",
    "# #                 val = (num - 60.5)\n",
    "# #                 print(num)\n",
    "#                 arduino_list.append(num)\n",
    "#             elif iterator%2 == 1:\n",
    "# #                 val = (num - 15)\n",
    "# #                 print(num)\n",
    "#                 arduino_list.append(num)\n",
    "#             iterator = iterator + 1\n",
    "#     #================================================\n",
    "# #     print(\"num of values in Arduino: \", len(arduino_list))\n",
    "    \n",
    "#     if  len(arduino_list) != 0:\n",
    "#         detector_list.append(x_coordinate)\n",
    "#         detector_list.append(y_coordinate)\n",
    "#         print(\"detected values: \")\n",
    "#         print(x_coordinate)\n",
    "#         print(y_coordinate)\n",
    "#         print(\"real values: \")\n",
    "#     cv2.show(\"123\", trans_image)\n",
    "   # Press 'q' to quit the program\n",
    "    # if True:\n",
    "    #     print(\"x: \" + \"{:.1f}cm\".format(x_coordinate) + \" y: {:.1f}cm\".format(y_coordinate))\n",
    "#         print(\"Object 0 center coordinates: ({}, {})\".format(center_x, center_y))\n",
    "#         print(\"Object 1 center coordinates: ({}, {})\".format(center_x1, center_y1))\n",
    "    if cv2.waitKey(1) == ord('p'):\n",
    "        print(\"detected values: \")\n",
    "        print(x_coordinate, y_coordinate)\n",
    "        detector_list.append(x_coordinate)\n",
    "        detector_list.append(y_coordinate)\n",
    "        \n",
    "    elif cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Release the video capture object and close all windows\n",
    "cap.release()   \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20f1f207-9607-4c3e-87a3-ac6bb00f19ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(\"milimetri7(bigger scale).txt\", \"w\")\n",
    "\n",
    "for i in range(len(detector_list)):\n",
    "    f.write(str(detector_list[i]) + ',')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "491efcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 60\n",
      "40 60\n",
      "20 60\n",
      "0 60\n",
      "60 40\n",
      "40 40\n",
      "20 40\n",
      "0 40\n",
      "60 20\n",
      "40 20\n",
      "20 20\n",
      "0 20\n",
      "60 0\n",
      "40 0\n",
      "20 0\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "y = 0\n",
    "ideal = []\n",
    "\n",
    "for i in range(3,-1,-1):\n",
    "    for j in range(3,-1,-1):\n",
    "        ideal.append(x + (20*j))\n",
    "        ideal.append(y + (20*i))\n",
    "        print(x + (20*j), y + (20*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46f92580",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"idealmilimetri7(bigger scale).txt\", \"w\")\n",
    "\n",
    "for i in range(len(ideal)):\n",
    "    f.write(str(ideal[i]) + ',')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afca6e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1280.  960.] [1487.  959.] [1488. 1168.] [1281. 1169.]\n",
      "10.350120544433594\n",
      "10.450119781494141\n",
      "10.350120544433594\n",
      "10.450119781494141\n"
     ]
    }
   ],
   "source": [
    "print(trans_marker[0], trans_marker[1], trans_marker[2], trans_marker[3])\n",
    "print(dist.euclidean(trans_marker[0], trans_marker[1]) / 20)\n",
    "print(dist.euclidean(trans_marker[1], trans_marker[2]) / 20)\n",
    "print(dist.euclidean(trans_marker[2], trans_marker[3]) / 20)\n",
    "print(dist.euclidean(trans_marker[3], trans_marker[0]) / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e96456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
